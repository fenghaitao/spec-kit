# Tasks: [FEATURE NAME]

**Input**: Design documents from `/specs/[###-feature-name]/`
**Prerequisites**: plan.md (required), research.md, data-model.md, contracts/

## Execution Flow (main)
```
1. Load plan.md from feature directory
   → If not found: ERROR "No implementation plan found"
   → Extract: tech stack, libraries, structure
2. Load optional design documents:
   → data-model.md: Extract entities → model tasks
   → contracts/: Each file → contract test task
   → research.md: Extract decisions → setup tasks
   → **Simics projects**: Extract register definitions → DML file tasks (after project structure is generated by MCP server)
3. Generate tasks by category:
   → Setup: project init, dependencies, linting
   → Tests: contract tests, integration tests
   → Core: models, services, CLI commands
   → Integration: DB, middleware, logging
   → Polish: unit tests, performance, docs
4. Apply task rules:
   → Different files = mark [P] for parallel
   → Same file = sequential (no [P])
   → Tests before implementation (TDD)
5. Number tasks sequentially (T001, T002...)
6. Generate dependency graph
7. Create parallel execution examples
8. Validate task completeness:
   → All contracts have tests?
   → All entities have models?
   → All endpoints implemented?
9. Return: SUCCESS (tasks ready for execution)
```

## Format: `[ID] [P?] Description`
- **[P]**: Can run in parallel (different files, no dependencies)
- Include exact file paths in descriptions

## Path Conventions
- **Single project**: `src/`, `tests/` at repository root
- **Web app**: `backend/src/`, `frontend/src/`
- **Mobile**: `api/src/`, `ios/src/` or `android/src/`
- **Simics**: `./simics-project/modules/device-name/`, `./simics-project/modules/device-name/test/` at repository root
- Paths shown below assume single project - adjust based on plan.md structure

## Phase 3.1: Setup
- [ ] T001 Create project structure per implementation plan
- [ ] T002 Initialize [language] project with [framework] dependencies
- [ ] T003 [P] Configure linting and formatting tools

**Simics Setup Example:**
- [ ] T001 Verify simics-mcp-server connection and Simics installation using `get_simics_version()`
- [ ] T002 Create Simics project structure using `create_simics_project(project_path="./simics-project")`
- [ ] T003 Add device skeleton using `add_dml_device_skeleton(project_path="./simics-project", device_name="DEVICE_NAME")`
- [ ] T004 [P] Verify project structure and build system using `build_simics_project(project_path="./simics-project", module="DEVICE_NAME")`
- [ ] T005 **CRITICAL**: Review and reference research.md for documented RAG search results (DML reference, Model Builder patterns, device templates, device-specific best practices, register patterns, test patterns)

## Phase 3.2: Tests First (TDD) ⚠️ MUST COMPLETE BEFORE 3.3
**CRITICAL: These tests MUST be written and MUST FAIL before ANY implementation**
- [ ] T004 [P] Contract test POST /api/users in tests/contract/test_users_post.py
- [ ] T005 [P] Contract test GET /api/users/{id} in tests/contract/test_users_get.py
- [ ] T006 [P] Integration test user registration in tests/integration/test_registration.py
- [ ] T007 [P] Integration test auth flow in tests/integration/test_auth.py

**Simics TDD Example:**
- [ ] T006 [P] Register access test in simics-project/modules/device-name/test/s-registers.py (reference test patterns from research.md)
- [ ] T007 [P] Interface behavior test in simics-project/modules/device-name/test/s-interfaces.py (reference interface patterns from research.md)
- [ ] T008 [P] Device workflow test in simics-project/modules/device-name/test/s-device-name.py (main test file, reference device patterns from research.md)
- [ ] T009 [P] Set up and validate test environment using `run_simics_test(project_path="./simics-project", suite="modules/DEVICE_NAME/test")`

## Phase 3.3: Core Implementation (ONLY after tests are failing)
- [ ] T008 [P] User model in src/models/user.py
- [ ] T009 [P] UserService CRUD in src/services/user_service.py
- [ ] T010 [P] CLI --create-user in src/cli/user_commands.py
- [ ] T011 POST /api/users endpoint
- [ ] T012 GET /api/users/{id} endpoint
- [ ] T013 Input validation
- [ ] T014 Error handling and logging

**Simics Implementation Example:**
- [ ] T010 [P] **RAG SEARCH**: Use `perform_rag_query("DML register read write implementation methods and callbacks", source_type="dml", match_count=5)` for detailed implementation guidance (OPTIONAL - if research.md insufficient)
- [ ] T011 [P] Register definitions in simics-project/modules/device-name/registers.dml (reference register patterns from research.md)
- [ ] T012 [P] Interface declarations in simics-project/modules/device-name/interfaces.dml (reference interface patterns from research.md)
- [ ] T013 [P] Build device module using `build_simics_project(project_path="./simics-project", module="DEVICE_NAME")`
- [ ] T014 Main device structure in simics-project/modules/device-name/device-name.dml (reference DML template from research.md)
- [ ] T015 **RAG SEARCH**: Use `perform_rag_query("device state management Simics", source_type="source", match_count=5)` for state handling patterns (OPTIONAL - if research.md insufficient)
- [ ] T016 Register read/write logic implementation
- [ ] T017 Device state management and attributes
- [ ] T018 Error handling and logging for device operations
- [ ] T019 [P] Incremental build validation using `build_simics_project(project_path="./simics-project", module="DEVICE_NAME")`

## Phase 3.4: Integration
- [ ] T015 Connect UserService to DB
- [ ] T016 Auth middleware
- [ ] T017 Request/response logging
- [ ] T018 CORS and security headers

**Simics Integration Example:**
- [ ] T029 **RAG SEARCH**: Use `perform_rag_query("Simics device interface integration", source_type="docs", match_count=5)` for integration patterns
- [ ] T030 Connect device to memory interface using transact() methods
- [ ] T031 Implement interrupt line connections and events
- [ ] T032 Add external port communications and protocols
- [ ] T033 Integrate with Simics checkpointing and state management
- [ ] T034 [P] Validate integration with `build_simics_project(project_path="./simics-project")`
- [ ] T035 [P] Run comprehensive tests using `run_simics_test(project_path="./simics-project", suite="modules/DEVICE_NAME/test")`
- [ ] T036 [P] Run comprehensive tests using `run_simics_test(project_path="./simics-project", suite="modules/DEVICE_NAME/test")`

## Phase 3.5: Polish
- [ ] T019 [P] Unit tests for validation in tests/unit/test_validation.py
- [ ] T020 Performance tests (<200ms)
- [ ] T021 [P] Update docs/api.md
- [ ] T022 Remove duplication
- [ ] T023 Run manual-testing.md

## Dependencies
- Tests (T004-T007) before implementation (T008-T014)
- T008 blocks T009, T015
- T016 blocks T018
- Implementation before polish (T019-T023)
### Simics Dependencies
- MCP server connection (T001) before project creation (T002)
- Project structure (T002) before device skeleton (T003)
- Device skeleton (T003) before build validation (T004)
- Build validation (T004) before research review (T005)
- Research review (T005) before test implementation (T006-T009)
- Tests (T006-T009) before implementation (T010-T019)
- Optional implementation RAG queries (T010, T015) only if research.md insufficient
- Device implementation (T011-T019) references patterns from research.md
- Error recovery RAG queries executed only when build errors occur

## Parallel Example
```
# Launch T004-T007 together:
Task: "Contract test POST /api/users in tests/contract/test_users_post.py"
Task: "Contract test GET /api/users/{id} in tests/contract/test_users_get.py"
Task: "Integration test registration in tests/integration/test_registration.py"
Task: "Integration test auth in tests/integration/test_auth.py"
```

## Notes
- [P] tasks = different files, no dependencies
- Verify tests fail before implementing
- Commit after each task
- Avoid: vague tasks, same file conflicts

## Task Generation Rules
*Applied during main() execution*

1. **From Contracts**:
   - Each contract file → contract test task [P]
   - Each endpoint → implementation task
   - **Simics**: Each register interface → register test task [P]

2. **From Data Model**:
   - Each entity → model creation task [P]
   - Relationships → service layer tasks
   - **Simics**: Each register group → DML file task [P]

3. **From User Stories**:
   - Each story → integration test [P]
   - Quickstart scenarios → validation tasks
   - **Simics**: Each device workflow → operational test [P]

4. **Ordering**:
   - Setup → Tests → Models → Services → Endpoints → Polish
   - **Simics**: MCP Setup → Tests → Registers → Interfaces → Device → Integration → Validation → Polish
   - Dependencies block parallel execution
   - **Simics MCP Tools**: Use at each validation step for continuous integration

## Validation Checklist
*GATE: Checked by main() before returning*

- [ ] All contracts have corresponding tests
- [ ] All entities have model tasks
- [ ] All tests come before implementation
- [ ] Parallel tasks truly independent
- [ ] Each task specifies exact file path
- [ ] No task modifies same file as another [P] task

**Simics-Specific Validation:**
- [ ] All MCP tool calls specify correct project_path
- [ ] Build validation tasks after implementation changes
- [ ] Test execution tasks use appropriate suite parameter
- [ ] Device name consistently used across MCP tool calls
- [ ] research.md from /plan phase is available and referenced
- [ ] Optional RAG searches are only used when research.md is insufficient
- [ ] All new RAG search results are documented

## Critical Prerequisites Gate
**⚠️ MANDATORY: research.md from /plan phase MUST be available before proceeding to Phase 3.2 (Tests)**

### Pre-Test Phase Gate Checklist:
- [ ] **GATE**: research.md file exists and is accessible from /plan phase
- [ ] **GATE T005**: research.md contains documented RAG results for:
  * DML 1.4 Reference Manual (source_type="docs")
  * Model Builder User Guide (source_type="docs")
  * DML Device Template (source_type="dml")
  * Device-Specific Best Practices (source_type="source")
  * Simics Device Reference Example (source_type="source")
  * Register Implementation Patterns (source_type="dml")
  * Simics Python Test Patterns (source_type="python")
  * Device Testing Best Practices (source_type="source")
- [ ] **GATE T005**: Reviewed research.md and understood the documented patterns and examples
- [ ] **GATE T005**: Identified which patterns from research.md apply to this specific implementation

### Execution Validation Rules:
1. **Prerequisites First**: T005 MUST verify research.md exists and contains all required RAG results from /plan phase
2. **Research Reference**: Implementation tasks should reference patterns documented in research.md
3. **Optional RAG Queries**: T010 and T015 are OPTIONAL - only use if research.md lacks specific implementation details
4. **New Query Documentation**: Any new RAG queries during tasks phase must be documented and added to research.md
5. **Blocking Dependency**: No Phase 3.2+ tasks can proceed until research.md is verified and reviewed

### Common Execution Failures:
- ❌ **Ignoring research.md**: Running duplicate RAG queries instead of using research.md from /plan phase
- ❌ **Skipping review**: Proceeding to implementation without reviewing documented patterns in research.md
- ❌ **Missing prerequisites**: Starting tasks without verifying /plan phase completed and generated research.md
- ❌ **Unnecessary queries**: Running RAG queries for information already documented in research.md
- ✅ **Correct approach**: Verify research.md exists → Review documented patterns → Reference during implementation → Only query if gaps exist

**Simics Error Recovery Rules:**
1. **If `build_simics_project` fails with syntax error**:
   - First, check research.md for relevant DML patterns and examples
   - If research.md lacks specific error-related examples, extract the syntax error keyword
   - Call `perform_rag_query(query="Examples of [syntax_error_keyword] in Simics DML 1.4", source_type="dml")`
   - Document the new RAG results before attempting to fix the DML files
   - Example: For "unknown attribute" error → check research.md first → query only if needed

```

## Critical RAG Search Execution Gate
**⚠️ MANDATORY: These RAG searches MUST be executed before proceeding to Phase 3.2 (Tests)**

### Pre-Test Phase Gate Checklist:
- [ ] **GATE T005**: `perform_rag_query("DML 1.4 reference manual register and device modeling", source_type="docs", match_count=5)` successfully executed with valid results
- [ ] **GATE T006**: `perform_rag_query("Simics Model Builder device creation and structure patterns", source_type="docs", match_count=5)` successfully executed with valid results
- [ ] **GATE T007**: `perform_rag_query("DML device template base structure and skeleton", source_type="dml", match_count=5)` successfully executed with valid DML patterns
- [ ] **GATE T008**: `perform_rag_query("Best practices for [DEVICE_NAME] device modeling with Simics DML 1.4", source_type="source", match_count=5)` successfully executed with device-specific patterns
- [ ] **GATE T009**: `perform_rag_query("Simics device implementation example [DEVICE_NAME] or similar peripheral", source_type="source", match_count=5)` successfully executed with reference examples
- [ ] **GATE T010**: `perform_rag_query("DML register bank implementation patterns", source_type="dml", match_count=5)` successfully executed with register patterns
- [ ] **GATE T011**: Retrieved RAG search results have been studied and documented for reference during implementation
- [ ] **GATE T012**: Validation confirms that all RAG searches returned non-empty, valid content with at least 3 relevant matches each

### Execution Validation Rules:
1. **Immediate Execution**: When T005-T010 are encountered, the `perform_rag_query()` calls MUST be executed immediately
2. **Success Verification**: Each RAG search must return valid content (at least 3 matches) before marking task complete
3. **Documentation Required**: Results must be saved and documented for later reference in implementation and test phases
4. **Source Type Specificity**: Use appropriate source_type for each query ("docs", "dml", "source", "python")
5. **Match Count**: Use match_count=5 for all searches to get focused, relevant results
6. **Blocking Dependency**: No Phase 3.2+ tasks can proceed until ALL setup RAG searches are successfully executed

### Common Execution Failures:
- ❌ **Stating intention without execution**: "Let's search with RAG" without actually invoking `perform_rag_query()`
- ❌ **Skipping to file operations**: Moving to task file updates instead of executing RAG searches
- ❌ **Assuming completion**: Marking tasks complete without verifying RAG execution and results
- ❌ **Wrong source_type**: Using incorrect source_type parameter (e.g., "all" instead of "dml" for DML-specific queries)
- ❌ **Wrong source_type**: Using source_type="all" when specific type (dml/python/source) would be more appropriate
- ✅ **Correct approach**: Execute MCP function/RAG search → Verify result → Access test samples → Document output → Mark complete

**Simics Error Recovery Rules:**
1. **If `build_simics_project` fails with syntax error**:
   - Extract the syntax error keyword from the error message
   - Call `perform_rag_query(query="Examples of [syntax_error_keyword] in Simics DML 1.4", source_type="dml")`
   - Study the returned examples before attempting to fix the DML files
   - Example: For "unknown attribute" error → query "Examples of unknown attribute in Simics DML 1.4"

2. **If `run_simics_test` fails**:
   - Extract the failure keyword from the test output
   - Call `perform_rag_query(query="Example of [test_failure_keyword] in Simics Python tests", source_type="python")`
   - Study the returned test examples before attempting to fix the tests
   - Example: For "AttributeError" → query "Example of AttributeError in Simics Python tests"
